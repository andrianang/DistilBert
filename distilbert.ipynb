{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from transformers import TFDistilBertModel, DistilBertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity</th>\n",
       "      <th>Content</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Borderlands</td>\n",
       "      <td>['i', 'am', 'coming', 'to', 'the', 'border', '...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Borderlands</td>\n",
       "      <td>['i', 'am', 'getting', 'on', 'borderland', 'an...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Borderlands</td>\n",
       "      <td>['i', 'am', 'coming', 'on', 'borderland', 'and...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Borderlands</td>\n",
       "      <td>['i', 'am', 'getting', 'on', 'borderland', '2'...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Borderlands</td>\n",
       "      <td>['i', 'am', 'getting', 'into', 'borderland', '...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51576</th>\n",
       "      <td>Nvidia</td>\n",
       "      <td>['my', 'be', 'no', 'highlight', 'picture', 're...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51577</th>\n",
       "      <td>Nvidia</td>\n",
       "      <td>['just', 'realized', 'that', 'my', 'mac', 'win...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51578</th>\n",
       "      <td>Nvidia</td>\n",
       "      <td>['just', 'realized', 'the', 'window', 'partiti...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51579</th>\n",
       "      <td>Nvidia</td>\n",
       "      <td>['just', 'realized', 'between', 'the', 'window...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51580</th>\n",
       "      <td>Nvidia</td>\n",
       "      <td>['just', 'like', 'the', 'window', 'partition',...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51581 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Entity                                            Content  \\\n",
       "0      Borderlands  ['i', 'am', 'coming', 'to', 'the', 'border', '...   \n",
       "1      Borderlands  ['i', 'am', 'getting', 'on', 'borderland', 'an...   \n",
       "2      Borderlands  ['i', 'am', 'coming', 'on', 'borderland', 'and...   \n",
       "3      Borderlands  ['i', 'am', 'getting', 'on', 'borderland', '2'...   \n",
       "4      Borderlands  ['i', 'am', 'getting', 'into', 'borderland', '...   \n",
       "...            ...                                                ...   \n",
       "51576       Nvidia  ['my', 'be', 'no', 'highlight', 'picture', 're...   \n",
       "51577       Nvidia  ['just', 'realized', 'that', 'my', 'mac', 'win...   \n",
       "51578       Nvidia  ['just', 'realized', 'the', 'window', 'partiti...   \n",
       "51579       Nvidia  ['just', 'realized', 'between', 'the', 'window...   \n",
       "51580       Nvidia  ['just', 'like', 'the', 'window', 'partition',...   \n",
       "\n",
       "      Sentiment  \n",
       "0      Positive  \n",
       "1      Positive  \n",
       "2      Positive  \n",
       "3      Positive  \n",
       "4      Positive  \n",
       "...         ...  \n",
       "51576  Positive  \n",
       "51577  Positive  \n",
       "51578  Positive  \n",
       "51579  Positive  \n",
       "51580  Positive  \n",
       "\n",
       "[51581 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('processed_train_df.csv')\n",
    "train_df = train_df[['Entity', 'en_content', 'Sentiment']]\n",
    "train_df.columns = ['Entity', 'Content', 'Sentiment']\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity</th>\n",
       "      <th>Content</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amazon</td>\n",
       "      <td>['broadcasting', 'corporation', 'news', 'amazo...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>['why', 'do', 'i', 'pay', 'for', 'word', 'when...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CS-GO</td>\n",
       "      <td>['matchmaking', 'is', 'so', 'full', 'of', 'clo...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Google</td>\n",
       "      <td>['now', 'the', 'president', 'is', 'slapping', ...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FIFA</td>\n",
       "      <td>['hi', 'i', 'had', 'in', 'my', 'cellar', 'for'...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>GrandTheftAuto(GTA)</td>\n",
       "      <td>['is', 'the', 'art', 'and', 'culture', 'capita...</td>\n",
       "      <td>Irrelevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>CS-GO</td>\n",
       "      <td>['this', 'is', 'actually', 'a', 'good', 'move'...</td>\n",
       "      <td>Irrelevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Borderlands</td>\n",
       "      <td>['today', 'sucked', 'so', 'it', 's', 'time', '...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>['bought', 'a', 'fraction', 'of', 'today', 'sm...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>johnson&amp;johnson</td>\n",
       "      <td>['to', 'stop', 'selling', 'talc', 'baby', 'pow...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>999 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Entity                                            Content  \\\n",
       "0                 Amazon  ['broadcasting', 'corporation', 'news', 'amazo...   \n",
       "1              Microsoft  ['why', 'do', 'i', 'pay', 'for', 'word', 'when...   \n",
       "2                  CS-GO  ['matchmaking', 'is', 'so', 'full', 'of', 'clo...   \n",
       "3                 Google  ['now', 'the', 'president', 'is', 'slapping', ...   \n",
       "4                   FIFA  ['hi', 'i', 'had', 'in', 'my', 'cellar', 'for'...   \n",
       "..                   ...                                                ...   \n",
       "994  GrandTheftAuto(GTA)  ['is', 'the', 'art', 'and', 'culture', 'capita...   \n",
       "995                CS-GO  ['this', 'is', 'actually', 'a', 'good', 'move'...   \n",
       "996          Borderlands  ['today', 'sucked', 'so', 'it', 's', 'time', '...   \n",
       "997            Microsoft  ['bought', 'a', 'fraction', 'of', 'today', 'sm...   \n",
       "998      johnson&johnson  ['to', 'stop', 'selling', 'talc', 'baby', 'pow...   \n",
       "\n",
       "      Sentiment  \n",
       "0       Neutral  \n",
       "1      Negative  \n",
       "2      Negative  \n",
       "3       Neutral  \n",
       "4      Negative  \n",
       "..          ...  \n",
       "994  Irrelevant  \n",
       "995  Irrelevant  \n",
       "996    Positive  \n",
       "997    Positive  \n",
       "998     Neutral  \n",
       "\n",
       "[999 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('processed_test_df.csv')\n",
    "test_df = test_df[['Entity', 'en_content', 'Sentiment']]\n",
    "test_df.columns = ['Entity', 'Content', 'Sentiment']\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "def combine_list(entity, lst):\n",
    "    actual_list = literal_eval(lst)\n",
    "    str_list = ' '.join(actual_list)\n",
    "\n",
    "    return f'{entity.lower()} : {str_list}'\n",
    "\n",
    "train_df.loc[:, 'Content'] = train_df.apply(lambda x: combine_list(x['Entity'], x['Content']), axis=1)\n",
    "test_df.loc[:, 'Content'] = test_df.apply(lambda x: combine_list(x['Entity'], x['Content']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertModel: ['vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing TFDistilBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFDistilBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer, TFDistilBertModel\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = TFDistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# # Load and preprocess the data\n",
    "data_train = train_df[['Content', 'Sentiment']]\n",
    "data_train['Sentiment_label'] = pd.Categorical(data_train['Sentiment'])\n",
    "data_train['Sentiment'] = data_train['Sentiment_label'].cat.codes\n",
    "\n",
    "# # Split the data into training and validation sets\n",
    "data_val = test_df[['Content', 'Sentiment']]\n",
    "data_val['Sentiment_label'] = pd.Categorical(data_val['Sentiment'])\n",
    "data_val['Sentiment'] = data_val['Sentiment_label'].cat.codes\n",
    "\n",
    "# Extract the training and validation texts and labels\n",
    "train_texts = data_train['Content'].tolist()\n",
    "train_labels = data_train['Sentiment'].tolist()\n",
    "val_texts = data_val['Content'].tolist()\n",
    "val_labels = data_val['Sentiment'].tolist()\n",
    "\n",
    "# Tokenize the texts\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=64)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=64)\n",
    "\n",
    "# Convert the labels to one-hot encoding\n",
    "num_labels = len(data_train['Sentiment_label'].cat.categories)\n",
    "train_labels_encoded = tf.one_hot(train_labels, num_labels)\n",
    "val_labels_encoded = tf.one_hot(val_labels, num_labels)\n",
    "\n",
    "# Create TensorFlow datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), train_labels_encoded))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((dict(val_encodings), val_labels_encoded))\n",
    "\n",
    "# Define the model architecture\n",
    "input_ids = tf.keras.layers.Input(shape=(64, ), dtype=tf.int32, name='input_ids')\n",
    "attention_mask = tf.keras.layers.Input(shape=(64, ), dtype=tf.int32, name='attention_mask')\n",
    "output = model(input_ids, attention_mask=attention_mask)[0]\n",
    "output = tf.keras.layers.Dense(num_labels, activation='softmax')(output[:, 0, :])  # Pooling the output\n",
    "model = tf.keras.Model(inputs=[input_ids, attention_mask], outputs=output)\n",
    "\n",
    "# Compile and train the model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-6)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)  # Set from_logits to False for softmax activation\n",
    "metrics = ['accuracy']\n",
    "\n",
    "# Define the ModelCheckpoint callback to save the best weights\n",
    "checkpoint_filepath = 'distilbert.h5'\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_best_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Use smaller batch size\n",
    "batch_size = 16\n",
    "epochs = 10\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "# Train the model with early stopping and model checkpoint\n",
    "history = model.fit(\n",
    "    train_dataset.batch(batch_size),\n",
    "    epochs=epochs,\n",
    "    validation_data=val_dataset.batch(batch_size),\n",
    "    callbacks=[model_checkpoint]\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "model.evaluate(val_dataset.batch(batch_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 10\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Load and preprocess the data\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# data_test = test_df[['Content', 'Sentiment']]\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# data_test['Sentiment_label'] = pd.Categorical(data_test['Sentiment'])\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# data_test['Sentiment'] = data_test['Sentiment_label'].cat.codes\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m test_texts \u001b[38;5;241m=\u001b[39m \u001b[43mdata_test\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContent\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m     11\u001b[0m test_labels \u001b[38;5;241m=\u001b[39m data_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSentiment\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m     13\u001b[0m test_encodings \u001b[38;5;241m=\u001b[39m tokenizer(test_texts, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m24\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_test' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import os\n",
    "\n",
    "# Load and preprocess the data\n",
    "data_test = test_df[['Content', 'Sentiment']]\n",
    "data_test['Sentiment_label'] = pd.Categorical(data_test['Sentiment'])\n",
    "data_test['Sentiment'] = data_test['Sentiment_label'].cat.codes\n",
    "\n",
    "test_texts = data_test['Content'].tolist()\n",
    "test_labels = data_test['Sentiment'].tolist()\n",
    "\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=24)\n",
    "\n",
    "# Convert the labels to one-hot encoding\n",
    "num_labels = len(data['Sentiment_label'].cat.categories)\n",
    "val_labels_encoded = tf.one_hot(val_labels, num_labels)\n",
    "test_labels_encoded = tf.one_hot(test_labels, num_labels)\n",
    "\n",
    "# Create TensorFlow datasets\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((dict(val_encodings), val_labels_encoded))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings), test_labels_encoded))\n",
    "\n",
    "val_predictions = model.predict(val_dataset.batch(64))\n",
    "val_predicted_labels = np.argmax(val_predictions, axis=1)\n",
    "test_predictions = model.predict(test_dataset.batch(64))\n",
    "test_predicted_labels = np.argmax(test_predictions, axis=1)\n",
    "\n",
    "# Convert the predicted labels to their original sentiment categories\n",
    "val_predicted_sentiments = data['Sentiment_label'].cat.categories[val_predicted_labels]\n",
    "test_predicted_sentiments = data['Sentiment_label'].cat.categories[test_predicted_labels]\n",
    "\n",
    "# Convert the true labels to their original sentiment categories\n",
    "val_true_labels = data_val['Sentiment_label']\n",
    "test_true_labels = data_test['Sentiment_label']\n",
    "\n",
    "# Calculate the classification report for the validation set\n",
    "val_classification_rep = classification_report(val_true_labels, val_predicted_sentiments)\n",
    "print(\"Validation Set - Classification Report:\\n\", val_classification_rep)\n",
    "\n",
    "# Generate the confusion matrix for the valing set\n",
    "val_confusion_mat = confusion_matrix(val_true_labels, val_predicted_sentiments)\n",
    "\n",
    "# Get the unique labels/categories from the true labels\n",
    "labels = np.unique(val_true_labels)\n",
    "\n",
    "\n",
    "save_folder = ''\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "val_classification_rep = classification_report(val_true_labels, val_predicted_sentiments)\n",
    "print(\"Validation Set - Classification Report:\\n\", val_classification_rep)\n",
    "\n",
    "val_report_path = os.path.join(save_folder, 'validation_classification_report.txt')\n",
    "with open(val_report_path, 'w') as file:\n",
    "    file.write(\"Validation Set - Classification Report:\\n\")\n",
    "    file.write(val_classification_rep)\n",
    "\n",
    "# Plot the confusion matrix for the validation set\n",
    "val_display = ConfusionMatrixDisplay(confusion_matrix=val_confusion_mat, display_labels=labels)\n",
    "val_display.plot(cmap='Blues')\n",
    "plt.title(\"Validation Set - Confusion Matrix\")\n",
    "plt.grid(False)\n",
    "val_image_path = os.path.join(save_folder, 'validation_confusion_matrix.png')\n",
    "plt.savefig(val_image_path)\n",
    "plt.show()\n",
    "\n",
    "# Calculate the classification report for the test set\n",
    "test_classification_rep = classification_report(test_true_labels, test_predicted_sentiments)\n",
    "print(\"Test Set - Classification Report:\\n\", test_classification_rep)\n",
    "\n",
    "# Save the classification report for the test set to a file\n",
    "test_report_path = os.path.join(save_folder, 'test_classification_report.txt')\n",
    "with open(test_report_path, 'w') as file:\n",
    "    file.write(\"Test Set - Classification Report:\\n\")\n",
    "    file.write(test_classification_rep)\n",
    "\n",
    "# Plot the confusion matrix for the test set\n",
    "test_display = ConfusionMatrixDisplay(confusion_matrix=test_confusion_mat, display_labels=labels)\n",
    "test_display.plot(cmap='Blues')\n",
    "plt.title(\"Test Set - Confusion Matrix\")\n",
    "plt.grid(False)\n",
    "test_image_path = os.path.join(save_folder, 'test_confusion_matrix.png')\n",
    "plt.savefig(test_image_path)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
